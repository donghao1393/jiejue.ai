---
title: "Как оптимизировать раздутые образы Docker"
date: 2025-02-08T18:49:54+04:00
slug: "docker-image-optimization"
draft: false
cover: "https://jiejue.obs.ap-southeast-1.myhuaweicloud.com/20250208185542747.webp"
tags:
  - "Docker"
  - "оптимизация производительности"
  - "DevOps"
---

Недавно при разработке веб-сервиса на Python мы обнаружили, что размер собранного образа Docker достигает 6 или 7 ГБ, что явно не является идеальным состоянием: огромные образы не только занимают много места в хранилище, но и снижают эффективность развертывания и повышают риск возникновения ошибок. В этой статье мы расскажем о том, как мы оптимизировали эту проблему.

<! -еще-->

## Анализ проблемы

Просмотрев журналы сборки, мы обнаружили следующие основные особенности:

1. базовый образ использует __PROTECTED_INLINE_CODE__3__, который является предустановленным образом nginx, uwsgi и flask
2. установка зависимостей Python заняла 87,5 секунды, что говорит о большом количестве пакетов зависимостей
3. процесс экспорта изображения занял 63,8 секунды, при этом экспорт слоя занял 49,8 секунды.
4. конечный локальный тестовый образ занимает около 3,6 ГБ, но в некоторых средах он может увеличиться до 6 или 7 ГБ.

## Исследование возможностей оптимизации

Мы предлагаем две идеи оптимизации:

### Вариант 1: Очистить кэш сборки

Этот вариант относительно прост и направлен на очистку кэша pip после установки зависимостей:

```dockerfile
RUN python -m pip install -r requirements.txt && \
    pip cache purge && \
    rm -rf /root/.cache/pip
```

### Вариант 2: Многоступенчатая сборка

Этот вариант более сложный и использует функцию многоступенчатой сборки Docker:

```dockerfile
# 构建阶段
FROM python:3.10-slim as builder
ENV PYTHONPATH=/usr/local
COPY requirements.txt .
RUN pip install --user -r requirements.txt && \
    find /root/.local -type d -name "tests" -exec rm -rf {} + && \
    find /root/.local -type d -name "__pycache__" -exec rm -rf {} +

# 运行阶段
FROM tiangolo/uwsgi-nginx-flask:python3.10
ENV PYTHONPATH=/usr/local
ENV PYTHONUNBUFFERED=1
COPY --from=builder /root/.local /root/.local
# ... 其他配置 ...
```.

## Сравнение и выбор схем

Мы провели реальные испытания двух схем и получили следующие результаты:

Вариант 1 (чистый кэш):
- Время сборки сократилось на 8 минут
- Размер зеркала уменьшился примерно на 6 ГБ
- Простое изменение, низкий риск

Вариант 2 (многоступенчатая сборка):
- Добавляет еще 6 минут к времени сборки по сравнению с вариантом 1
- Сокращение дополнительного пространства всего на 0,3 ГБ
- Сложное изменение, требует рефакторинга Dockerfile.

В конечном итоге мы выбрали вариант 1, основываясь на соотношении входных и выходных данных. Этот процесс принятия решений отражает несколько важных принципов инженерной практики:

1. количественная оценка: не слепое следование "лучшим практикам", а получение данных путем реального тестирования.
2. постепенная оптимизация: начните с простого плана оптимизации, оцените результаты и затем решите, нужен ли более сложный план.
3. поиск компромиссов: найти баланс между эффективностью оптимизации, сложностью реализации и стоимостью обслуживания.

## Обработка контроля версий

Попробовав второй вариант, мы решили вернуться к первому. Вместо того чтобы использовать `git push -f` для принудительного push, мы создали новый revert commit, чтобы сохранить целостность истории git:

```bash
$ git revert HEAD

# 提交信息
revert: multi-stage build optimization

The multi-stage build optimization increased build time by 6 minutes
while only reducing image size by 0.3G compared to the pip cache
cleanup solution. Reverting to keep the more efficient approach.
```

Эта процедура сохраняет полную запись процесса принятия решения и предоставляет ценную справочную информацию для остальных членов команды.

## Выученные уроки

1. оптимизация образов Docker не должна стремиться к совершенству, необходимо найти баланс между эффективностью и стоимостью
2. прежде чем принимать сложные решения, следует опробовать простые оптимизации
3. решения должны быть основаны на реальных тестовых данных, а не на теоретических "лучших практиках".
4. операции контроля версий должны учитывать необходимость командной работы и поддерживать целостность исторических записей.

Подобная оптимизационная работа есть везде, главное - создать научную методологию принятия решений: сформулировать гипотезу, собрать данные, проверить эффект и извлечь уроки из опыта. Это более ценно, чем конкретные технические средства.
