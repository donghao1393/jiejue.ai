---
title: "Элегантная обработка журнальных файлов с помощью awk: от введения к практике"
date: 2025-02-23T10:51:32+04:00
slug: "awk-log-processing-guide"
draft: false
cover: "https://jiejue.obs.ap-southeast-1.myhuaweicloud.com/20250223105350142.webp"
tags:
  - "Linux"
  - "обработка текста"
  - "AWK"
  - "анализ журнала"
---

В повседневной работе нам часто приходится иметь дело с лог-файлами различных форматов. Иногда формат журнала не является идеальным, и нам необходимо выполнить преобразование и обработку, чтобы лучше проанализировать данные. Сегодня я расскажу вам, как использовать awk, мощный инструмент обработки текста, для элегантной обработки лог-файлов.

<! --подробнее-->

## Сценарий проблемы

Предположим, у нас есть файл журнала, генерируемый приложением, в котором каждая запись содержит временную метку, тип события, объект операции и информацию о соответствующем процессе. Оригинальный формат журнала выглядит следующим образом:

```
2025-02-23 15:30:48.078 | Event: CREATE, Path: example.txt
相关进程:
AppOne(com.example.one)[最近活跃]
系统桌面(com.android.launcher)[最近活跃]
设置(com.android.settings)[最近活跃]

2025-02-23 15:31:01.218 | Event: MODIFY, Path: config.ini
相关进程:
AppTwo(com.example.two)[最近活跃]
系统桌面(com.android.launcher)[最近活跃]
...
```.

Этот формат, хотя и легко читается человеческим глазом, не способствует последующему анализу с помощью наших инструментов. Мы хотим:

1. отфильтровать операции над определенными файлами (например, только файлы .txt и .ini)
2. сохранять только первый релевантный процесс (обычно тот, который действительно работает)
3. организовать информацию в виде таблиц, которые можно легко импортировать в другие инструменты.

## Решение

Давайте напишем пошаговый awk-сценарий для обработки этого лог-файла.

### Шаг 1: Базовая структура

Для начала нам понадобится базовая структура скрипта:

```fish
set raw_log my_app.log  # 设置日志文件路径
awk '
BEGIN {
    # 打印表头
    printf("%-23s | %-12s | %-8s | %-20s | %s\n",
           "TIMESTAMP", "EVENT", "PATH", "APP", "PACKAGE")
    # 打印分隔线
    printf("%.90s\n", "------------------------------------------------------------------------------------------------------------------------------------------------")
}
# 后续处理逻辑会加在这里
' $raw_log
```.

Этот фреймворк делает две вещи:
1. определяет структуру таблицы вывода
2. форматирует вывод, используя `printf`, чтобы обеспечить выравнивание столбцов

### Шаг 2: Сопоставление ключевых строк

Далее нам нужно найти строки, содержащие интересующий нас файл:

```awk
/Path:.*(txt|ini)/ {  # 匹配包含 txt 或 ini 的 Path 行
    # 保存这一行，后面会处理
    event_line = $0
    # 读取下一行
    getline
    if ($0 ~ /相关进程:/) {  # 检查是否是进程信息行
        getline  # 再读取一行得到第一个进程
        process = $0
        # 后续处理...
    }
}
```

Этот код:
1. использует регулярное выражение для поиска строки, содержащей указанный тип файла
2. использовать `getline` для чтения последующих строк, чтобы получить информацию о процессе.
3. сохраните необходимую информацию в переменной.

### Шаг 3: Извлечение информации

Теперь давайте извлечем нужную нам информацию:

```awk
# 提取时间戳
timestamp = $1" "$2

# 提取事件类型
match($0, /Event: [^,]+/)
event_type = substr($0, RSTART+7, RLENGTH-7)

# 提取文件路径
match($0, /Path: [^ |]+/)
path = substr($0, RSTART+6, RLENGTH-6)

# 提取进程信息
match($0, /[^(]+\([^)]+\)/)
full_proc = substr($0, RSTART, RLENGTH)
split(full_proc, parts, "(")
app_name = parts[1]
package = substr(parts[2], 1, length(parts[2])-1)
```

Здесь используется несколько важных функций awk:
- `match()`: находит совпадающий шаблон в строке.
- `substr()`: извлекает подстроку.
- `split()`: разбиение строки на части

### Шаг 4: Форматирование вывода

Наконец, мы выводим извлеченную информацию в отформатированном виде:

```awk
printf("%s | %-12s | %-8s | %-20s | %s\n", 
       timestamp, event_type, path, app_name, package)
```

Описание форматирования:
- `%s`: заполнитель строки
- `-12s`: выравнивание по левому краю, ширина строки 12
- `\n`: символ переноса строки

## Полный сценарий

Если собрать все вышеперечисленные части вместе, то получится полный скрипт обработки:

```fish
set raw_log my_app.log
awk '
BEGIN {
    printf("%-23s | %-12s | %-8s | %-20s | %s\n",
           "TIMESTAMP", "EVENT", "PATH", "APP", "PACKAGE")
    printf("%.90s\n", "------------------------------------------------------------------------------------------------------------------------------------------------")
}
/Path:.*(txt|ini)/ {
    # 提取时间戳 
    timestamp = $1" "$2
    # 提取事件类型
    match($0, /Event: [^,]+/)
    event_type = substr($0, RSTART+7, RLENGTH-7)
    # 提取路径
    match($0, /Path: [^ |]+/)
    path = substr($0, RSTART+6, RLENGTH-6)
    # 读取进程信息
    getline
    if ($0 ~ /相关进程:/) {
        getline
        # 提取进程名和包名
        match($0, /[^(]+\([^)]+\)/)
        full_proc = substr($0, RSTART, RLENGTH)
        # 分割进程名和包名
        split(full_proc, parts, "(")
        app_name = parts[1]
        package = substr(parts[2], 1, length(parts[2])-1)
        # 输出格式化的日志
        printf("%s | %-12s | %-8s | %-20s | %s\n", 
               timestamp, event_type, path, app_name, package)
    }
}' $raw_log
```

Запустив этот скрипт, мы получим следующий результат:

```
TIMESTAMP               | EVENT        | PATH     | APP                  | PACKAGE
------------------------------------------------------------------------------------------
2025-02-23 15:30:48.078 | CREATE       | test.txt | AppOne              | com.example.one
2025-02-23 15:31:01.218 | MODIFY       | app.ini  | AppTwo              | com.example.two
```

## Практические советы

1. **Тестирование регулярных выражений**: При написании сложных регулярных выражений вы можете сначала протестировать их с помощью `echo` и `grep`:
   ```bash
   echo "your test string" | grep "your regex"
   ```.

2. **Отладочный вывод**: утверждения `print` могут быть использованы для отладки во время разработки:
   ```awk
   print "Debug:", $0  # 打印当前行
   ```

3. **Сохранять промежуточные результаты**: При работе с большими файлами можно сначала обработать небольшую часть для тестирования:
   ```fish
   head -n 100 big_log.txt | awk '你的脚本' > test_output.txt
   ```

## Резюме

На этом примере мы узнали:
1. основной синтаксис и функции использования awk
2. как работать с многострочным протоколированием
3. как извлекать и форматировать выходные данные

Этот сценарий можно использовать в качестве шаблона, который можно легко адаптировать к другим подобным задачам ведения журнала, изменив регулярные выражения и формат вывода. Надеюсь, это руководство поможет вам лучше понять и использовать awk для обработки лог-файлов.
