<!doctype html><html lang=zh-cn x-data :class=$store.darkMode.class() :data-theme=$store.darkMode.theme()><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>突破 Azure Log Analytics 导出限制：百万级日志提取实战 | 爱解决</title><link href=/favicon.ico rel=icon type=image/x-icon><link rel=canonical href=https://jiejue.ai/2025/12/azure-log-analytics-export-millions-rows/><meta name=author content="董昊"><meta name=description content="当你需要从 Azure Log Analytics 导出数百万行日志进行离线分析时，会发现 Azure Portal 的 3 万行限制远远不够。本文介绍一种通过 Azure Data Explorer 代理突破限制的方法，并提供完整的分批导出策略。
"><meta name=keywords content="Azure,Log Analytics,KQL,DevOps"><meta name=generator content="Hugo 0.154.2"><meta property="og:url" content="https://jiejue.ai/2025/12/azure-log-analytics-export-millions-rows/"><meta property="og:site_name" content="爱解决"><meta property="og:title" content="突破 Azure Log Analytics 导出限制：百万级日志提取实战"><meta property="og:description" content="当你需要从 Azure Log Analytics 导出数百万行日志进行离线分析时，会发现 Azure Portal 的 3 万行限制远远不够。本文介绍一种通过 Azure Data Explorer 代理突破限制的方法，并提供完整的分批导出策略。"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-19T22:21:21+04:00"><meta property="article:modified_time" content="2025-12-19T22:31:41+04:00"><meta property="article:tag" content="Azure"><meta property="article:tag" content="Log Analytics"><meta property="article:tag" content="KQL"><meta property="article:tag" content="DevOps"><meta name=twitter:card content="summary"><meta name=twitter:title content="突破 Azure Log Analytics 导出限制：百万级日志提取实战"><meta name=twitter:description content="当你需要从 Azure Log Analytics 导出数百万行日志进行离线分析时，会发现 Azure Portal 的 3 万行限制远远不够。本文介绍一种通过 Azure Data Explorer 代理突破限制的方法，并提供完整的分批导出策略。"><link rel=stylesheet href=/css/output.min.css><style>pre{padding:1em;overflow:auto}</style><script defer src=https://cdn.jsdelivr.net/npm/alpinejs@3.15.1/dist/cdn.min.js integrity="sha256-Rmqrc5SKeSLTSnQ9shSKWmJco1ks8c1hLI8UG2Np03M=" crossorigin=anonymous></script></head><body x-data="{
    flip: false,
  }"><div id=dream-global-bg></div><nav x-data="{ isSticky: false }" x-init="window.addEventListener('scroll', () => { isSticky = window.scrollY > 30 })" class="sticky top-0 z-30 mt-4 lg:mt-8 py-4" :class="{ 'bg-base-100 shadow-lg dark:border-b dark:border-base-content/30': isSticky }"><div class="container flex justify-between px-4"><section class="flex items-center gap-4"><div class="avatar cursor-pointer hover:avatar-online" @click="flip = !flip" title=翻转一下！><div class="h-10 rounded-full"><img src=/favicon.ico alt=爱解决></div></div><div><a href=https://jiejue.ai/ class="text-lg font-semibold cursor-pointer">爱解决</a><div class="text-base-content/60 text-sm">用AI为人民服务</div></div></section><div class="dropdown dropdown-end sm:hidden"><div tabindex=0 role=button class="btn btn-ghost btn-square" aria-label="Select an option"><ion-icon name=menu class=text-2xl></ion-icon></div><ul tabindex=0 class="dropdown-content menu w-36 bg-base-100 rounded-box z-1 shadow-md"><li><a class="group inline-flex items-center p-2 cursor-pointer" href=/search title=搜索><ion-icon name=search></ion-icon>搜索</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/index.xml title=RSS><ion-icon name=logo-rss></ion-icon>RSS</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/posts title=归档><ion-icon name=archive></ion-icon>归档</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/tags title=所有标签><ion-icon name=pricetags></ion-icon>所有标签</a></li></ul></div><section class="hidden sm:flex sm:items-center sm:gap-2 md:gap-4"><a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href=/search title=搜索><ion-icon class=group-hover:text-primary-content name=search></ion-icon></a><a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href=/index.xml title=RSS><ion-icon class=group-hover:text-primary-content name=logo-rss></ion-icon></a><div class="dropdown dropdown-end dropdown-hover"><div tabindex=0 role=button class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" aria-label="Select an option"><ion-icon class="group-hover:text-primary-content text-xl" name=menu></ion-icon></div><ul tabindex=0 class="dropdown-content menu w-36 bg-base-100 rounded-box z-1 shadow-xl"><li><a class="inline-flex items-center p-2 cursor-pointer" href=/posts title=归档><ion-icon name=archive></ion-icon>归档</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/tags title=所有标签><ion-icon name=pricetags></ion-icon>所有标签</a></li></ul></div></section></div></nav><div class=flip-container :class="{ 'flip-it': flip }"><div class=flipper><div class=front><div class=container><div class="lg:grid lg:grid-cols-4 gap-4 mt-4 px-4"><div class="hidden lg:block"></div><div class=lg:col-span-2><article class="mx-auto prose prose-quoteless dark:prose-invert" id=dream-single-post-main itemscope itemtype=http://schema.org/Article><meta itemprop=name content="突破 Azure Log Analytics 导出限制：百万级日志提取实战"><meta itemprop=description content="当你需要从 Azure Log Analytics 导出数百万行日志进行离线分析时，会发现 Azure Portal 的 3 万行限制远远不够。本文介绍一种通过 Azure Data Explorer 代理突破限制的方法，并提供完整的分批导出策略。"><meta itemprop=datePublished content="2025-12-19T22:21:21+04:00"><meta itemprop=dateModified content="2025-12-19T22:31:41+04:00"><meta itemprop=wordCount content="1441"><meta itemprop=keywords content="Azure,Log Analytics,KQL,DevOps"><header><h1 itemprop=headline>突破 Azure Log Analytics 导出限制：百万级日志提取实战</h1><p class=text-sm><span data-format=luxon>2025-12-19T22:21:21+04:00</span>
| <span>3分钟阅读</span>
| <span>更新于
<span data-format=luxon>2025-12-19T22:31:41+04:00</span></span></p><div class="flex justify-between"><div class="flex items-center"><span>@</span>
<span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=name>董昊</span></span></div><div class="flex items-center gap-2"><a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="https://x.com/intent/post?text=%e7%aa%81%e7%a0%b4%20Azure%20Log%20Analytics%20%e5%af%bc%e5%87%ba%e9%99%90%e5%88%b6%ef%bc%9a%e7%99%be%e4%b8%87%e7%ba%a7%e6%97%a5%e5%bf%97%e6%8f%90%e5%8f%96%e5%ae%9e%e6%88%98&amp;url=https://jiejue.ai/2025/12/azure-log-analytics-export-millions-rows/" target=_blank rel="noopener noreferrer" title="Share on X"><ion-icon class=group-hover:text-primary-content name=logo-x></ion-icon></a><a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="https://facebook.com/sharer/sharer.php?u=https://jiejue.ai/2025/12/azure-log-analytics-export-millions-rows/" target=_blank rel="noopener noreferrer" title="Share on Facebook"><ion-icon class=group-hover:text-primary-content name=logo-facebook></ion-icon></a><a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="https://wa.me/?text=%e7%aa%81%e7%a0%b4%20Azure%20Log%20Analytics%20%e5%af%bc%e5%87%ba%e9%99%90%e5%88%b6%ef%bc%9a%e7%99%be%e4%b8%87%e7%ba%a7%e6%97%a5%e5%bf%97%e6%8f%90%e5%8f%96%e5%ae%9e%e6%88%98%20https://jiejue.ai/2025/12/azure-log-analytics-export-millions-rows/" target=_blank rel="noopener noreferrer" title="Share on WhatsApp"><ion-icon class=group-hover:text-primary-content name=logo-whatsapp></ion-icon></a></div></div></header><section id=dream-single-post-content itemprop=articleBody><figure><img class=z-30 src=https://jiejue.obs.ap-southeast-1.myhuaweicloud.com/20251219222444282.webp alt="突破 Azure Log Analytics 导出限制：百万级日志提取实战"></figure><p>当你需要从 Azure Log Analytics 导出数百万行日志进行离线分析时，会发现 Azure Portal 的 3 万行限制远远不够。本文介绍一种通过 Azure Data Explorer 代理突破限制的方法，并提供完整的分批导出策略。</p><h2 id=问题的本质>问题的本质</h2><p>Azure Log Analytics 的导出限制并非技术缺陷，而是服务端的资源保护机制。不同访问路径有不同的硬限制：</p><table><thead><tr><th>访问方式</th><th>行数限制</th><th>字节限制</th><th>超时</th></tr></thead><tbody><tr><td>Azure Portal</td><td>30,000</td><td>64MB</td><td>10分钟</td></tr><tr><td>REST API / Logic Apps</td><td>500,000</td><td>64MB</td><td>10分钟</td></tr><tr><td>ADX 代理 (ade.loganalytics.io)</td><td>500,000</td><td>64MB</td><td>10分钟</td></tr></tbody></table><p>Portal 的 3 万行限制是最严格的。如果你的数据量在 50 万行以内，通过 ADX 代理可以一次性导出；超过 50 万行，则需要分批处理。</p><h2 id=azure-data-explorer-代理被低估的导出通道>Azure Data Explorer 代理：被低估的导出通道</h2><p>Azure 提供了一个鲜为人知的功能：通过 Azure Data Explorer Web UI 直接查询 Log Analytics workspace。这个代理通道将行数限制从 3 万提升到 50 万，且支持更灵活的导出格式。</p><h3 id=连接-uri-格式>连接 URI 格式</h3><p><a href=https://ade.loganalytics.io/subscriptions/%7bsubscription-id%7d/resourcegroups/%7bresource-group%7d/providers/microsoft.operationalinsights/workspaces/%7bworkspace-name%7d target=_blank>https://ade.loganalytics.io/subscriptions/{subscription-id}/resourcegroups/{resource-group}/providers/microsoft.operationalinsights/workspaces/{workspace-name}</a></p><h3 id=连接步骤>连接步骤</h3><ol><li>打开 <a href=https://dataexplorer.azure.com target=_blank>Azure Data Explorer Web UI</a></li><li>点击左侧 &ldquo;Add connection&rdquo;</li><li>选择 &ldquo;Connection URI&rdquo;</li><li>粘贴上述格式的 URI（替换为你的实际值）</li><li>使用 Azure AD 认证登录</li></ol><p>连接成功后，你可以使用与 Portal 完全相同的 KQL 语法查询数据，但享受更高的导出限制。</p><h2 id=分批导出策略>分批导出策略</h2><p>当数据量超过 50 万行时，必须采用时间切片策略。核心思路是：先分析数据的时间分布，然后将高峰时段切分成更小的时间窗口。</p><h3 id=第一步分析数据分布>第一步：分析数据分布</h3><pre tabindex=0><code class=language-kql data-lang=kql>ContainerLogV2
| where PodNamespace contains &#34;your-namespace&#34;
| where TimeGenerated &gt;= datetime(2025-01-15T00:00:00Z)
| summarize count() by bin(TimeGenerated, 1h)
| order by TimeGenerated asc
</code></pre><p>这个查询返回每小时的日志数量，帮助你识别高峰时段。</p><h3 id=第二步估算总量>第二步：估算总量</h3><pre tabindex=0><code class=language-kql data-lang=kql>ContainerLogV2
| where PodNamespace contains &#34;your-namespace&#34;
| where TimeGenerated &gt;= datetime(2025-01-15T00:00:00Z)
| summarize TotalRows = count()
</code></pre><h3 id=第三步设计切片方案>第三步：设计切片方案</h3><p>根据分布情况，将时间段切分为若干批次，确保每批不超过 50 万行。高峰时段需要更细的切分粒度。</p><p>以下是一个实际案例的切分方案：</p><p><strong>高峰时段（每批 20 分钟）：</strong></p><pre tabindex=0><code class=language-kql data-lang=kql>// 批次 1: UTC 09:20-09:40
ContainerLogV2
| where PodNamespace contains &#34;ecommerce&#34;
| where PodName contains &#34;order-service&#34;
| where TimeGenerated &gt;= datetime(2025-01-15T09:20:00Z) 
    and TimeGenerated &lt; datetime(2025-01-15T09:40:00Z)
| sort by TimeGenerated asc
| project LogMessage
</code></pre><p><strong>低峰时段（每批数小时）：</strong></p><pre tabindex=0><code class=language-kql data-lang=kql>// 批次 6: UTC 11:00-19:00
ContainerLogV2
| where PodNamespace contains &#34;ecommerce&#34;
| where PodName contains &#34;order-service&#34;
| where TimeGenerated &gt;= datetime(2025-01-15T11:00:00Z) 
    and TimeGenerated &lt; datetime(2025-01-15T19:00:00Z)
| sort by TimeGenerated asc
| project LogMessage
</code></pre><h3 id=第四步执行导出>第四步：执行导出</h3><p>在 ADX Web UI 中执行查询后，点击 &ldquo;Export&rdquo; 按钮，选择 CSV 或 TSV 格式下载。重复此过程直到所有批次完成。</p><h2 id=优化查询以减少字节消耗>优化查询以减少字节消耗</h2><p>64MB 的字节限制意味着即使行数未达 50 万，也可能因数据体积过大而失败。使用 <code>project</code> 操作符仅选择必要的列：</p><pre tabindex=0><code class=language-kql data-lang=kql>// 只提取日志消息，忽略元数据
ContainerLogV2
| where PodNamespace contains &#34;your-namespace&#34;
| where TimeGenerated &gt;= datetime(2025-01-15T00:00:00Z)
| project LogMessage
</code></pre><p>对比完整查询，字节消耗可降低 80% 以上。</p><h2 id=关于-set-语句的误解>关于 set 语句的误解</h2><p>你可能在网上看到类似的建议：</p><pre tabindex=0><code class=language-kql data-lang=kql>set truncationmaxsize = 1073741824;
set truncationmaxrecords = 5000000;
</code></pre><p>这些语句在<strong>直连自建 ADX 集群</strong>时确实有效，但通过 <code>ade.loganalytics.io</code> 代理访问 Log Analytics 时，服务端会覆盖这些设置。50 万行和 64MB 是硬限制，无法通过客户端参数突破。</p><h2 id=kubernetes-日志的特殊性>Kubernetes 日志的特殊性</h2><p>如果你的目标是 AKS 容器日志，需要注意一个关键事实：Kubernetes 节点上的日志文件会定期轮转和清理。一旦 Pod 被销毁或节点重建，原始日志文件就不复存在。</p><p>Log Analytics 是这些日志的唯一持久化存储。不要指望从 Kubernetes 集群直接提取历史日志——如果没有被采集到 Log Analytics，那些日志就永远消失了。</p><h2 id=自动化方案>自动化方案</h2><p>对于需要定期导出的场景，可以使用 Azure CLI 配合脚本实现自动化：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#75715e># 分批导出脚本示例</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>WORKSPACE_ID<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;your-workspace-id&#34;</span>
</span></span><span style=display:flex><span>START_DATE<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;2025-01-15&#34;</span>
</span></span><span style=display:flex><span>END_DATE<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;2025-01-16&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 按小时循环</span>
</span></span><span style=display:flex><span>current<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$START_DATE<span style=color:#e6db74> T00:00:00Z&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> <span style=color:#f92672>[[</span> <span style=color:#e6db74>&#34;</span>$current<span style=color:#e6db74>&#34;</span> &lt; <span style=color:#e6db74>&#34;</span>$END_DATE<span style=color:#e6db74> T00:00:00Z&#34;</span> <span style=color:#f92672>]]</span>; <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    next<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>date -d <span style=color:#e6db74>&#34;</span>$current<span style=color:#e6db74> + 1 hour&#34;</span> -Iseconds<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    az monitor log-analytics query <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span>        --workspace <span style=color:#e6db74>&#34;</span>$WORKSPACE_ID<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span>        --analytics-query <span style=color:#e6db74>&#34;ContainerLogV2 | where TimeGenerated &gt;= datetime(</span>$current<span style=color:#e6db74>) and TimeGenerated &lt; datetime(</span>$next<span style=color:#e6db74>) | project LogMessage&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span>        --output tsv &gt;&gt; <span style=color:#e6db74>&#34;logs_</span><span style=color:#66d9ef>$(</span>date -d <span style=color:#e6db74>&#34;</span>$current<span style=color:#e6db74>&#34;</span> +%Y%m%d_%H<span style=color:#66d9ef>)</span><span style=color:#e6db74>.tsv&#34;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    current<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$next<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span></code></pre></div><p>注意：Azure CLI 同样受 50 万行限制约束，脚本需要根据实际数据密度调整时间窗口大小。</p><h2 id=总结>总结</h2><p>从 Azure Log Analytics 导出百万级日志的核心策略：</p><ol><li>使用 ADX 代理 (dataexplorer.azure.com) 替代 Portal，将行数限制从 3 万提升到 50 万</li><li>分析数据的时间分布，识别高峰和低峰时段</li><li>设计分批方案，确保每批不超过 50 万行</li><li>使用 <code>project</code> 仅选择必要列，减少字节消耗</li><li>逐批执行并下载</li></ol><p>这套方法已在实际生产环境中验证，成功导出了超过 500 万行容器日志。</p><hr><p><em>如果你需要更频繁地进行大规模日志分析，考虑配置 <a href=https://learn.microsoft.com/en-us/azure/azure-monitor/logs/logs-data-export target=_blank>Data Export Rules</a>
将日志持续导出到 Storage Account 或 Event Hub——但请注意，该功能只能导出配置后产生的新数据，无法回溯历史。</em></p></section><div class=divider></div><div class="flex flex-col md:flex-row justify-between gap-4 py-4"><a role=button class="btn btn-outline h-12" href=/2025/12/bun-javascript-runtime-intro/ title="Bun：一个想要终结 JavaScript 工具链混乱的野心家"><ion-icon name=chevron-back></ion-icon><div class="inline-flex flex-col items-start"><span class="text-base-content/60 text-xs font-normal">上一页</span>
<span class="max-w-48 truncate">Bun：一个想要终结 JavaScript 工具链混乱的野心家</span></div></a><a role=button class="btn btn-outline h-12" href=/2025/12/mac-app-uninstall-complete-guide/ title=Mac应用卸载的正确姿势：告别系统残留><div class="inline-flex flex-col items-end"><span class="text-base-content/60 text-xs font-normal">下一页</span>
<span class="max-w-48 truncate">Mac应用卸载的正确姿势：告别系统残留</span></div><ion-icon name=chevron-forward></ion-icon></a></div><div class=divider></div><section class=space-y-4><article><div id=tcomment></div><script src=https://cdn.jsdelivr.net/npm/twikoo@1.6.41/dist/twikoo.min.js></script><script>twikoo.init({envId:"https://6dhzwvtyqz753zhpkrvnnydhlm0vubmy.lambda-url.ap-east-1.on.aws/",el:"#tcomment",region:"ap-east-1",path:"/2025/12/azure-log-analytics-export-millions-rows/",lang:"zh-CN"})</script></article></section></article></div><div x-data=tocHighlighter() @scroll.window=debouncedScroll class="hidden lg:flex lg:flex-col lg:items-end"><nav id=TableOfContents><ul><li><a href=#问题的本质>问题的本质</a></li><li><a href=#azure-data-explorer-代理被低估的导出通道>Azure Data Explorer 代理：被低估的导出通道</a><ul><li><a href=#连接-uri-格式>连接 URI 格式</a></li><li><a href=#连接步骤>连接步骤</a></li></ul></li><li><a href=#分批导出策略>分批导出策略</a><ul><li><a href=#第一步分析数据分布>第一步：分析数据分布</a></li><li><a href=#第二步估算总量>第二步：估算总量</a></li><li><a href=#第三步设计切片方案>第三步：设计切片方案</a></li><li><a href=#第四步执行导出>第四步：执行导出</a></li></ul></li><li><a href=#优化查询以减少字节消耗>优化查询以减少字节消耗</a></li><li><a href=#关于-set-语句的误解>关于 set 语句的误解</a></li><li><a href=#kubernetes-日志的特殊性>Kubernetes 日志的特殊性</a></li><li><a href=#自动化方案>自动化方案</a></li><li><a href=#总结>总结</a></li></ul></nav></div></div><footer class="flex justify-between items-center gap-2 px-4 py-12"><div><p>© 2025 - 2026 爱解决</p><p>硅基生物幼稚园</p></div><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><section><span id=busuanzi_container_value_site_pv><i class="far fa-eye fa-fw"></i>
本站总访问量 <span id=busuanzi_value_site_pv></span>
</span>&nbsp;|&nbsp;
<span id=busuanzi_container_value_site_uv><i class="fa fa-user"></i>
本站访客数 <span id=busuanzi_value_site_uv></span></span></section></span></section></script><div x-data="{ icons: [
    { name: 'sunny', status: 'n' },
    { name: 'moon', status: 'y' },
    { name: 'desktop', status: 'auto' }
  ] }" class="flex items-center gap-2 h-[32px] px-2 bg-base-100 border border-base-content/30 rounded-full"><template x-for="icon in icons"><div role=button tabindex=0 :aria-label="'Select ' + icon.name + ' mode'" class="group inline-flex justify-center items-center p-1 rounded-full cursor-pointer hover:bg-primary" :class="$store.darkMode.icon() === icon.name && 'bg-primary'" @click=$store.darkMode.toggle(icon.status)><ion-icon :name="`${icon.name}-outline`" class=group-hover:text-primary-content :class="$store.darkMode.icon() === icon.name && 'text-primary-content'"></ion-icon></div></template></div></footer></div></div><div class=back><div class=container><div class="dream-grid dream-grid-about"></div><footer class="flex justify-between items-center gap-2 px-4 py-12"><div><p>© 2025 - 2026 爱解决</p><p>硅基生物幼稚园</p></div><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><section><span id=busuanzi_container_value_site_pv><i class="far fa-eye fa-fw"></i>
本站总访问量 <span id=busuanzi_value_site_pv></span>
</span>&nbsp;|&nbsp;
<span id=busuanzi_container_value_site_uv><i class="fa fa-user"></i>
本站访客数 <span id=busuanzi_value_site_uv></span></span></section></span></section></script><div x-data="{ icons: [
    { name: 'sunny', status: 'n' },
    { name: 'moon', status: 'y' },
    { name: 'desktop', status: 'auto' }
  ] }" class="flex items-center gap-2 h-[32px] px-2 bg-base-100 border border-base-content/30 rounded-full"><template x-for="icon in icons"><div role=button tabindex=0 :aria-label="'Select ' + icon.name + ' mode'" class="group inline-flex justify-center items-center p-1 rounded-full cursor-pointer hover:bg-primary" :class="$store.darkMode.icon() === icon.name && 'bg-primary'" @click=$store.darkMode.toggle(icon.status)><ion-icon :name="`${icon.name}-outline`" class=group-hover:text-primary-content :class="$store.darkMode.icon() === icon.name && 'text-primary-content'"></ion-icon></div></template></div></footer></div></div></div></div><script>window.lightTheme="emerald",window.darkTheme="forest"</script><script src=https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin=anonymous></script><script src=/js/grid.min.js></script><script src=/js/main.min.js></script><script src=https://cdn.jsdelivr.net/npm/luxon@1.26.0 integrity="sha256-4sbTzmCCW9LGrIh5OsN8V5Pfdad1F1MwhLAOyXKnsE0=" crossorigin=anonymous></script><script>format();function format(){document.querySelectorAll('span[data-format="luxon"]').forEach(e=>{const t=e.textContent;e.textContent=luxon.DateTime.fromISO(t,{locale:"zh"}).toFormat("yyyy年MM月dd日 HH:mm")})}</script><script src=/js/toc.min.js></script><script type=module>
      import mediumZoom from 'https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/+esm';
      mediumZoom('#dream-single-post-content img', {
        background: 'oklch(var(--b1))',
        margin: 24,
      })
    </script><script async src="https://www.googletagmanager.com/gtag/js?id=G-S0KCH9BW4F"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-S0KCH9BW4F")}</script><script type=module src=https://cdn.jsdelivr.net/npm/ionicons@7.4.0/dist/ionicons/ionicons.esm.js integrity="sha256-/IFmi82bIhdYWctu0UddSlJqpnzWm7Vh2C4CM32wF/k=" crossorigin=anonymous></script><script nomodule src=https://cdn.jsdelivr.net/npm/ionicons@7.4.0/dist/ionicons/ionicons.js integrity="sha256-mr7eJMX3VC3F7G32mk4oWp1C6a2tlMYxUdptfT7uKI8=" crossorigin=anonymous></script></body></html>